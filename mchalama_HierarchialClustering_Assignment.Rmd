---
title: "R Notebook"
output:
  html_document:
    df_print: paged
  word_document: default
---
```{r}
library(readr)
library(tidyverse)
library(factoextra)
library(cluster)
library(knitr)
library(caret)
library(dendextend)
```

Read the data

```{r}
Cereals <- read_csv("Cereals.csv")
head(Cereals)
set.seed(15)
```

# Data Preprocessing. Remove all cereals with missing values

```{r}
# Number of missing values
sum(is.na(Cereals))
# Remove all cereals with missing values
MyData <- na.omit(Cereals)
#str(MyData)
```

# Normalization and Scale the Data

```{r}
Cerealnames <- MyData$name
# Drop the Categorical Columns
MyData <- MyData[, c(-1, -2, -3)]
MyData <- scale(MyData, center = T, scale = T)
head(MyData)
```


# 1. Apply hierarchical clustering to the data using Euclidean distance to the normaliMyDataed measurements. Use Agnes to compare the clustering from  single linkage, complete linkage, average linkage, and Ward. Choose the best method.

```{r}
# Dissimilarity matrix
d <- dist(MyData, method = "euclidean")

# Hierarchical clustering using Complete Linkage
hc1 <- hclust(d, method = "complete" )

# Plot the obtained dendrogram
plot(hc1, cex = 0.6, hang = -1)

# Compute with agnes and with different linkage methods
hc_single <- agnes(MyData, method = "single")
hc_complete <- agnes(MyData, method = "complete")
hc_average <- agnes(MyData, method = "average")
hc_ward <- agnes(MyData, method = 'ward')

pltree(hc_complete, cex = 0.6, hang = -1, main = "Dendrogram of agnes", labels = Cerealnames) 
```

```{r}
# Compare Agglomerative Coefficients

m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# function to compute coefficient

ac <- function(x) {
  agnes(MyData, method = x)$ac
}

map_dbl(m, ac)
```

# On comparing the best method is 'Ward'

```{r}
# Dissimilarity matrix
d1 <- dist(MyData, method = "euclidean")

# Hierarchical clustering using Ward Linkage
hc2 <- hclust(d1, method = "ward.D2" )

# Plot the obtained dendrogram
plot(hc2)
```


# 2. How many clusters would you choose?

```{r}
# Elbow method to chosse K
fviz_nbclust(MyData, FUN = hcut, method = "wss")
```

# Not able to determine K based on Elbow methid.
# Let's try based on Dendogram using rect.hclust method by cutting the tree into 4 clusters

```{r}
# Cut the tree to 4 clusters, using the cutree() function
hc3 <- cutree(hc2, k = 4)

# Number of Cereals in each cluster
table(hc3)

# Store the clusters in a data frame along with the cereals data

cereals_hc <- cbind(hc3, MyData)

# We can also use the cutree output to add the the cluster each observation belongs to to our original data.

colnames(cereals_hc)[1] <- "cluster"

head(cereals_hc)

plot(hc2)

rect.hclust(hc2, k = 4, border = 2:4)
```

# Based on the dendogram above the optimal value of K is 4 since 4 boxes are cut properly on the graph.

# c. Comment on the structure of the clusters and on their stability. Hint: To check stability,  partition the data and see how well clusters formed based on one part apply to the other part. To do this:
Cluster partition A
Use the cluster centroids from A to assign each record in partition B (each record is assigned to the cluster with the closest centroid).
Assess how consistent the cluster assignments are compared to the assignments based on all the data.

```{r}
# Checking the stability of the cluster 
newdata<-Cereals
newdata1<-na.omit(newdata)
#newdata_index<-createDataPartition(newdata1$calories,p=0.75,list=FALSE)
train_data<-newdata1[1:60,] # Partition A
test_data<-newdata1[61:74,] # Partition B


NormTrain_Data <- scale(train_data[, -c(1:3)])
NormTest_Data <- scale(test_data[, -c(1:3)])

#For Partition A the best mwethod is "ward" 
hc11<- agnes(scale(train_data[,-c(1:3)]),method = "ward")
hc12<-agnes(scale(train_data[,-c(1:3)]),method="average")
hc13<-agnes(scale(train_data[,-c(1:3)]),method="complete")
hc14<-agnes(scale(train_data[,-c(1:3)]),method="single")
kable(cbind(ward=hc11$ac,average=hc12$ac,complete=hc13$ac,single=hc14$ac))


pltree(hc11,cex=0.6,hang=-1,main="Dendrogram of agnes",labels = train_data$name)
rect.hclust(hc11, k = 4, border = 2:4)

clust2<-cutree(hc11, k=4)

result<-as.data.frame(cbind(NormTrain_Data,clust2))

# Determine centroids for all 4 clusters
centroid1<-data.frame(column=seq(1,13,1),mean=rep(0,13))
centroid2<-data.frame(column=seq(1,13,1),mean=rep(0,13))
centroid3<-data.frame(column=seq(1,13,1),mean=rep(0,13))
centroid4<-data.frame(column=seq(1,13,1),mean=rep(0,13))
for(i in 1:13)
{
  centroid1[i,2]<-mean(result[result$clust2==1,i])
  centroid2[i,2]<-mean(result[result$clust2==2,i])
  centroid3[i,2]<-mean(result[result$clust2==3,i])
  centroid4[i,2]<-mean(result[result$clust2==4,i])
}
centroidResult<-t(cbind(centroid1$mean,centroid2$mean,centroid3$mean,centroid4$mean)) 
colnames(centroidResult)<-colnames(newdata1[,-c(1:3)]) 

centroidResult 


Dumm1 <- data.frame(data=seq(1,14,1), cluster=rep(0,14))
for(i in 1:14)
{
  R <- as.data.frame(rbind(centroidResult,NormTest_Data[i,]))
  U <- as.matrix(get_dist(R))
  Dumm1[i,2] <- which.min(U[5,-5])
  
}
Dumm1

NewClusterData <- as.data.frame(cereals_hc[61:74,])

cbind(Label1 = Dumm1$cluster, Label2 = NewClusterData$cluster)

table(Dumm1$cluster == NewClusterData$cluster)

```

Out of 14 rows 13 are True. Accuarcy is 92%. Hence stability of cluster is 92%.

# d. The elementary public schools would like to choose a set of cereals to include in their daily cafeterias. Every day a different cereal is offered, but all cereals should support a healthy diet. For this goal, you are requested to find a cluster of “healthy cereals.” Should the data be normalized? If not, how should they be used in the cluster analysis?

```{r}
MyDataResult<-cbind(newdata1,hc3)
MyDataResult[MyDataResult$hc3==1,]
MyDataResult[MyDataResult$hc3==2,]
MyDataResult[MyDataResult$hc3==3,]
MyDataResult[MyDataResult$hc3==4,]
```

# From the above Cluster 1 has highest ratings. So Cluster 1 is a cluster of "Healthy Cereals"
